{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Origin-Destination Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import timeit\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - Downloads each state OD data from the remote site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(filename, counter):\n",
    "    print ('\\nCurrently processing #', counter, filename)\n",
    "    dataframe = pd.read_csv(filename, dtype=str)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function - Convert decimal time to minutes and seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(timer):\n",
    "    minutes, seconds = int(np.floor(timer)), round(np.asscalar(timer % 1)*60)\n",
    "    return[minutes,  seconds]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list of state abbreviations\n",
    "To be used to identify the files to extract from remote site. Of use in the loop below.  \n",
    "Puerto Rico (pr), Virgin Island (vi), and Wyoming (wy) do not have data for 2015"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_list = ['ak', 'al', 'ar', 'az', 'ca', 'co', 'ct', 'dc', 'de', 'fl', 'ga', 'hi', 'ia', 'id', 'il', 'in', 'ks',\n",
    "              'ky', 'la', 'ma', 'md', 'me', 'mi', 'mn', 'mo', 'ms', 'mt', 'nc', 'nd', 'ne', 'nh', 'nj', 'nm', 'nv',\n",
    "              'ny', 'oh', 'ok', 'or', 'pa', 'ri', 'sc', 'sd', 'tn', 'tx', 'ut', 'va', 'vt', 'wa', 'wi', 'wv']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop through each state, download the compressed file, extract data, append to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Processing Complete\n",
      "Total time: 10 minutes 10 seconds \n",
      "Total count: 115,682,106\n"
     ]
    }
   ],
   "source": [
    "# set various counting variables\n",
    "counter = 0\n",
    "decimals = 0   \n",
    "# start a timer\n",
    "start = timeit.default_timer()\n",
    "# create a blank list to accumulate the dataframes\n",
    "df_list = []\n",
    "count_records = 0\n",
    "\n",
    "for st in state_list:\n",
    "    # file and path of download\n",
    "    filename = 'https://lehd.ces.census.gov/data/lodes/LODES7/'+ st + '/od/' + st + '_od_main_JT01_2015.csv.gz'\n",
    "    \n",
    "    # call function to load compressed data into datafram\n",
    "    df = get_data(filename, counter)\n",
    "    \n",
    "    # count records in current list\n",
    "    count_records = count_records+len(df)\n",
    "\n",
    "    # clear the output below this cell\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # get the current time on timer\n",
    "    stop = timeit.default_timer()\n",
    "    timer = np.array([(stop-start)/60])\n",
    "    min_sec = get_time(timer)\n",
    "    minutes, seconds = min_sec[0], min_sec[1]\n",
    "    \n",
    "    # print a few lines for progress monitoring\n",
    "    print('Processed state OD file:',st.upper())\n",
    "    print('Length of dataframe:',\"{:,}\".format(len(df)))\n",
    "    print('Current record count:', \"{:,}\".format(count_records),'\\n')\n",
    "    print('Timer:', minutes, 'minutes', seconds, 'seconds')\n",
    "    counter+=1\n",
    "    \n",
    "    # append df to list before next state overwrites df\n",
    "    df_list.append(df)\n",
    "\n",
    "        \n",
    "for st in state_list:\n",
    "    # file and path of download\n",
    "    filename = 'https://lehd.ces.census.gov/data/lodes/LODES7/'+ st + '/od/' + st + '_od_aux_JT01_2015.csv.gz'\n",
    "    #https://lehd.ces.census.gov/data/lodes/LODES7/ak/od/ak_od_aux_JT01_2015.csv.gz\n",
    "    \n",
    "    # call function to load compressed data into dataframe\n",
    "    df = get_data(filename, counter)\n",
    "    \n",
    "    # count records in current list\n",
    "    count_records = count_records+len(df)\n",
    "\n",
    "    # clear the output below this cell\n",
    "    clear_output(wait=True)\n",
    "    \n",
    "    # get the current time on timer\n",
    "    stop = timeit.default_timer()\n",
    "    timer = np.array([(stop-start)/60])\n",
    "    min_sec = get_time(timer)\n",
    "    minutes, seconds = min_sec[0], min_sec[1]\n",
    "    \n",
    "    # print a few lines for progress monitoring\n",
    "    print('Processed state AUX file:',st.upper())\n",
    "    print('Length of dataframe:',\"{:,}\".format(len(df)))\n",
    "    print('Current record count:', \"{:,}\".format(count_records),'\\n')\n",
    "    print('Timer:', minutes, 'minutes', seconds, 'seconds')\n",
    "    counter+=1\n",
    "    \n",
    "    # append df to list before next state overwrites df\n",
    "    df_list.append(df)\n",
    "\n",
    "# clear the output below this cell\n",
    "clear_output(wait=True)\n",
    "print('\\n\\nProcessing Complete\\nTotal time:', minutes, 'minutes', seconds, 'seconds',\n",
    "      '\\nTotal count:', \"{:,}\".format(count_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a dataframe containing all OD records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%time df_out = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove Unnecessary column(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 54.8 s\n"
     ]
    }
   ],
   "source": [
    "%time df_out.drop(['createdate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 115682106 entries, 0 to 81999\n",
      "Data columns (total 12 columns):\n",
      "w_geocode    object\n",
      "h_geocode    object\n",
      "S000         object\n",
      "SA01         object\n",
      "SA02         object\n",
      "SA03         object\n",
      "SE01         object\n",
      "SE02         object\n",
      "SE03         object\n",
      "SI01         object\n",
      "SI02         object\n",
      "SI03         object\n",
      "dtypes: object(12)\n",
      "memory usage: 11.2+ GB\n"
     ]
    }
   ],
   "source": [
    "df_out.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create directory path for output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPath = Path(\"../data/OD/\")\n",
    "outputPath.mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputZip = 'od_aux.csv.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create full path with zip file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_Zip = outputPath.joinpath(outputZip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Write dataframe to compressed CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Data compression complete.\n",
      "Total time: 22 minutes 14 seconds\n"
     ]
    }
   ],
   "source": [
    "# start a timer\n",
    "start = timeit.default_timer()\n",
    "print ('Compressing dataframe. Please be patient.')\n",
    "df_out.to_csv(out_Zip, compression='gzip', index=None)\n",
    "clear_output(wait=True)\n",
    "# get the current time on timer\n",
    "stop = timeit.default_timer()\n",
    "timer = np.array([(stop-start)/60])\n",
    "min_sec = get_time(timer)\n",
    "minutes, seconds = min_sec[0], min_sec[1]\n",
    "print('\\nData compression complete.\\nTotal time:', minutes, 'minutes', seconds, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
